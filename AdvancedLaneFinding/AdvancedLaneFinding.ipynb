{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "In order to manipulate a car I need to measure how much my lane is curving. To do that I need to map out the lanes in my camera image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "\n",
    "def arrange_side_by_side(img1, img2, title1, title2):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 30))\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(title1)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(title2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Camera Calibration and Distortion Coefficients\n",
    "Camera image has distortions. This means camera image does not represent perfectly real world objects. There is two types of distortion, Radial Distortion and Tangental Distortion.\n",
    "\n",
    "To get a curvature of lane lines based on real world I need to correct those distortions, before I map out the lane lines from a camera image,.\n",
    "\n",
    "To correct distortions I need to calculate some parameters.\n",
    " - distortion coefficients (k1, k2, p1, p2, k3)\n",
    " - camera matrix ([[fx, 0, xc], [0, fy, yc], [0, 0, 1]]) <= intrinsic parameters\n",
    " - extrinsic parameters (rotation and translation vector)\n",
    " \n",
    "To find those parameters I'll do calibration through chessboard images.\n",
    " 1. detect image points on 2D chessboard image space using findChessboardCorners() function\n",
    " 2. prepare object points on 3D real world space which indicate same points with 1st step.\n",
    " 3. get parameters for correcting image distortion using calibrateCamera() function.\n",
    " 4. finally correct distortions using undistort() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'camera_cal/calibration2.jpg'\n",
    "img = mpimg.imread(fname)\n",
    "\n",
    "img_origin = np.copy(img)\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.imshow(img_gray, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st step: find image points on 2D chessboard image\n",
    "pattern_size = (9, 6)\n",
    "found, image_points_base = cv2.findChessboardCorners(img_gray, pattern_size, None)\n",
    "\n",
    "# checking\n",
    "cv2.drawChessboardCorners(img, pattern_size, image_points_base, found)\n",
    "arrange_side_by_side(img_origin, img, 'original image', 'draw corners')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd step: prepare object points\n",
    "object_points_base = np.zeros((pattern_size[0]*pattern_size[1], 3), np.float32)\n",
    "object_points_base[:,:2] = np.mgrid[0:pattern_size[0], 0:pattern_size[1]].T.reshape((-1, 2))\n",
    "\n",
    "# x = np.arange(pattern_size[0])\n",
    "# y = np.arange(pattern_size[1])\n",
    "# xx, yy = np.meshgrid(x,y)\n",
    "# object_points_base = [[xx[i][j], yy[i][j], 0] for j in range(pattern_size[0]) for i in range(pattern_size[1])]\n",
    "\n",
    "object_points = []\n",
    "image_points = []\n",
    "\n",
    "if found:\n",
    "    object_points.append(object_points_base)\n",
    "    image_points.append(image_points_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3rd step: calibrate camera to get parameters for undistortion\n",
    "try:\n",
    "    r, cam_mtx, dist_coeff, rvecs, tvecs = cv2.calibrateCamera(object_points, image_points, img.shape[1::-1], None, None)\n",
    "except:\n",
    "    print('Exception occured at calibrateCamera function!!\\nPlease check the parameters.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4th step: Undistortion\n",
    "undist_img = cv2.undistort(img_origin, cam_mtx, dist_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the result\n",
    "arrange_side_by_side(img_origin, undist_img, 'original', 'undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thresholded Binary Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sobel(img, orientation='x'):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orientation == 'x':\n",
    "        sobel = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0)\n",
    "    elif orientation == 'y':\n",
    "        sobel = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1)\n",
    "    else:\n",
    "        print(\"Unknown value of orientation.\")\n",
    "        return None\n",
    "    abs_img = np.absolute(sobel)\n",
    "    return abs_img * 255 / np.max(abs_img)\n",
    "\n",
    "def filter_sobel_gradient_magnitude(img, ksize=3):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    grad_mag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    return grad_mag * 255 / np.max(grad_mag)\n",
    "\n",
    "def filter_gradient_direction(img, ksize=3):\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=ksize))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=ksize))\n",
    "    return np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "def filter_hls(rgb_img, channel='s'):\n",
    "    if channel == 'h':\n",
    "        c = 0\n",
    "    elif channel == 'l':\n",
    "        c = 1\n",
    "    elif channel == 's':\n",
    "        c = 2\n",
    "    else:\n",
    "        print(\"Undefined parameter channel\")\n",
    "    hls = cv2.cvtColor(rgb_img, cv2.COLOR_RGB2HLS)\n",
    "    return hls[:,:,c]\n",
    "\n",
    "def create_binary_image(img, thresh_min=50, thresh_max=100):\n",
    "    binary = np.zeros_like(img)\n",
    "    binary[(img > thresh_min) & (img < thresh_max)] = 1\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Sobel filter for y direction\n",
    "#sobelx = filter_sobel(rimg, 'x')\n",
    "#binary_sobelx = create_binary_image(sobelx, 15, 140)\n",
    "#\n",
    "#arrange_side_by_side(rimg, binary_sobelx, 'Origin', 'BinaryX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the Sobel filter for y direction\n",
    "#sobely = filter_sobel(rimg, 'y')\n",
    "#binary_sobely = create_binary_image(sobely, 20, 150)\n",
    "#\n",
    "#arrange_side_by_side(rimg, binary_sobely, 'Origin', 'Binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_mag = filter_sobel_gradient_magnitude(rimg, ksize=5)\n",
    "binary_grad_mag = create_binary_image(grad_mag, 30, 170)\n",
    "\n",
    "arrange_side_by_side(rimg, binary_grad_mag, 'Origin', 'Gradient Magnitude Thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grad_dir = filter_gradient_direction(rimg, ksize=11)\n",
    "binary_grad_dir = create_binary_image(grad_dir, 0.8, 1.3)\n",
    "\n",
    "arrange_side_by_side(rimg, binary_grad_dir, 'Origin', 'Gradient Direction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_img = filter_hls(rimg, 's')\n",
    "binary_satulate = create_binary_image(s_img, 150, 300)\n",
    "arrange_side_by_side(rimg, binary_satulate, 'Origin', 'Satulate Channel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the above binary images\n",
    "binary = np.zeros_like(binary_grad_dir)\n",
    "binary[((binary_grad_mag == 1) & (binary_grad_dir == 1) | (binary_satulate == 1))] = 1\n",
    "\n",
    "arrange_side_by_side(rimg, binary, 'Origin', 'Combined Binary Image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "src = np.float32(\n",
    "    [[840, 546],\n",
    "     [1051, 677],\n",
    "     [244, 686],\n",
    "     [453, 546]])\n",
    "dst = np.float32(\n",
    "    [[1051, 463],\n",
    "     [1051, 686],\n",
    "     [245, 686],\n",
    "     [245, 463]])\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src, dst)\n",
    "Minv = cv2.getPerspectiveTransform(dst, src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = cv2.warpPerspective(binary, M, (rimg.shape[1], rimg.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "\n",
    "arrange_side_by_side(rimg, warped, 'Original', 'Bird Eyes View')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Windows to plot lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_point_likely(img):\n",
    "    hist = np.sum(img[img.shape[0]//2:, :], axis=0)\n",
    "    center_horizontal = img.shape[1]//2\n",
    "    left = np.argmax(hist[:center_horizontal])\n",
    "    right = np.argmax(hist[center_horizontal:]) + center_horizontal\n",
    "    return left, right\n",
    "\n",
    "def search_lane_line_pixels(img, left_start, right_start, draw_rect=False):\n",
    "    margin = 100\n",
    "    n_window = 9\n",
    "    minpix_thresh = 50\n",
    "    \n",
    "    nonzero = img.nonzero()\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "\n",
    "    # output place holders\n",
    "    left_lane_pixels = []\n",
    "    right_lane_pixels = []\n",
    "    out_img = np.dstack((img, img, img)) * 255\n",
    "    \n",
    "    for i in range(n_window):\n",
    "        bottom = img.shape[0] - img.shape[0]//n_window * i\n",
    "        top = bottom - img.shape[0]//n_window\n",
    "        l_left = left_start - margin\n",
    "        l_right = left_start + margin\n",
    "        r_left = right_start - margin\n",
    "        r_right = right_start + margin\n",
    "        \n",
    "        if draw_rect:\n",
    "            cv2.rectangle(out_img, (l_left, top), (l_right, bottom), (0,255,0), 2)\n",
    "            cv2.rectangle(out_img, (r_left, top), (r_right, bottom), (0,255,0), 2)\n",
    "        \n",
    "        left_inds = ((nonzero_y > top) & (nonzero_y < bottom) & (nonzero_x > l_left) & (nonzero_x < l_right)).nonzero()[0]\n",
    "        right_inds = ((nonzero_y > top) & (nonzero_y < bottom) & (nonzero_x > r_left) & (nonzero_x < r_right)).nonzero()[0]\n",
    "        left_lane_pixels.append(left_inds)\n",
    "        right_lane_pixels.append(right_inds)\n",
    "        \n",
    "        if len(left_inds > minpix_thresh):\n",
    "            left_start = np.int(np.mean(nonzero_x[left_inds]))\n",
    "        if len(right_inds > minpix_thresh):\n",
    "            right_start = np.int(np.mean(nonzero_x[right_inds]))\n",
    "            \n",
    "    try:\n",
    "        left_lane_pixels = np.concatenate(left_lane_pixels)\n",
    "        right_lane_pixels = np.concatenate(right_lane_pixels)\n",
    "    except ValueError:\n",
    "        pass\n",
    "    \n",
    "    lx = nonzero_x[left_lane_pixels]\n",
    "    ly = nonzero_y[left_lane_pixels]\n",
    "    rx = nonzero_x[right_lane_pixels]\n",
    "    ry = nonzero_y[right_lane_pixels]\n",
    "    \n",
    "    out_img[ly, lx] = [255, 0, 0]\n",
    "    out_img[ry, rx] = [0, 0, 255]\n",
    "    \n",
    "    return lx, ly, rx, ry ,out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quadratic_plots(img, quad_coef):\n",
    "    ploty = np.linspace(0, img.shape[0]-1, img.shape[0])\n",
    "    try:\n",
    "        plotx = quad_coef[0]*ploty**2 + quad_coef[1]*ploty + quad_coef[2]\n",
    "    except TypeError:\n",
    "        plotx = 1*ploty**2 + 1*ploty\n",
    "    return ploty, plotx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blind search execution\n",
    "starting_point_l, starting_point_r = get_starting_point_likely(warped)\n",
    "lx, ly, rx, ry, rect_drawed = search_lane_line_pixels(warped, starting_point_l, starting_point_r, True)\n",
    "\n",
    "coeff_left = np.polyfit(ly, lx, 2)\n",
    "coeff_right = np.polyfit(ry, rx, 2)\n",
    "ploty, plotx_l = get_quadratic_plots(warped, coeff_left)\n",
    "ploty, plotx_r = get_quadratic_plots(warped, coeff_right)\n",
    "\n",
    "plt.imshow(rect_drawed)\n",
    "plt.plot(plotx_l, ploty, color='yellow')\n",
    "plt.plot(plotx_r, ploty, color='yellow')\n",
    "plt.xlim(0, rect_drawed.shape[1])\n",
    "plt.ylim(rect_drawed.shape[0], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the previous polynomial to skip the sliding window\n",
    "So far I did the blind search. However using the full alforithm from before and starting fresh on every frame may seem inefficient, as the lane lines don't necessarily move a lot from frame to frame.\n",
    "\n",
    "Instead I can just search in a margin around the previous lane line position. So, once I know where the lines are in one frame of video I can do a highly targeted search for them in the next frame.\n",
    "\n",
    "And this way should help me track the lanes through sharp curves and tricky conditions. If I lose track of the lines, go back to my sliding windos search or other method to rediscover them.\n",
    "\n",
    "To hold the pixel values contained within the boundaries of a given sliding window I used the variables called <code>left_lane_pixels</code> and <code>right_lane_pixels</code>. This time, we'll take the polynomial functions I fit before, along with a hyperparameter <code>margin</code>, to determine whivh activated pixcels fall into the green shaded areas from the avobe image.\n",
    "\n",
    "To implement this, I'll want to grab only those pixels with x values that are +/- my margin from my polynomial lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_search_area_idx(prev_binary, prev_coefs, margin=100):\n",
    "    idx_nonzero = prev_binary.nonzero()\n",
    "    idx_nonzero_y = np.array(idx_nonzero[0])\n",
    "    idx_nonzero_x = np.array(idx_nonzero[1])\n",
    "    prev_polynomial = prev_coefs[0] * idx_nonzero_y**2 + prev_coefs[1] * idx_nonzero_y + prev_coefs[2]\n",
    "    is_target = (prev_polynomial-margin < idx_nonzero_x) & (prev_polynomial+margin > idx_nonzero_x)\n",
    "    idx_nonzero_y = idx_nonzero_y[is_target]\n",
    "    idx_nonzero_x = idx_nonzero_x[is_target]\n",
    "    return idx_nonzero_y, idx_nonzero_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quadratic_coefficient(binary_image, ym_per_pix, xm_per_pix):\n",
    "    nonzero = np.nonzero(binary_image)\n",
    "    nonzero_y = nonzero[0]\n",
    "    nonzero_x = nonzero[1]\n",
    "    return np.polyfit(nonzero_y* ym_per_pix, nonzero_x*xm_per_pix, 2)\n",
    "\n",
    "def search_polynomial_around_prior(new_binary_image, target_y, target_x, ym_per_pix=1, xm_per_pix=1):\n",
    "    new_image = np.zeros_like(new_binary_image)\n",
    "    new_image[target_y, target_x] = 1\n",
    "    coefficient = get_quadratic_coefficient(new_image, ym_per_pix, xm_per_pix)\n",
    "    return coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_ly, target_lx = get_search_area_idx(warped, coeff_left, 80)\n",
    "target_ry, target_rx = get_search_area_idx(warped, coeff_right, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = np.copy(warped)\n",
    "coeff_left = search_polynomial_around_prior(new_image, target_ly, target_lx)\n",
    "coeff_right = search_polynomial_around_prior(new_image, target_ry, target_rx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ploty, plotx_l = get_quadratic_plots(warped, coeff_left)\n",
    "ploty, plotx_r = get_quadratic_plots(warped, coeff_right)\n",
    "\n",
    "plt.imshow(new_image, cmap='gray')\n",
    "plt.plot(plotx_l, ploty, color='red')\n",
    "plt.plot(plotx_r, ploty, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Curvature\n",
    "Next I'll compute the radius of curvature of a polinomial. I'm fitting for f(y), rather than f(x), because the lane lines in the warped image are near vartical and may have the same x value for more than one y value.\n",
    "\n",
    "### Radius of Curvature\n",
    "The radius of curvature at any point x of the function x=f(y) is given as follows:\n",
    "\n",
    "    f(y) = Ay**2 + By + C = x\n",
    "    Rcurve = [1+(dx/dy)**2]**3/2 / |d**2x/dy**2|\n",
    "    \n",
    "In the case of the second order polynomial above, the first and second derivatives are:\n",
    "\n",
    "    f'(y) = dx/dy = 2Ay + B\n",
    "    f\"(y) = d**2x/dy**2 = 2A\n",
    "   \n",
    "So, our equation for radius of curvature becomes:\n",
    "    \n",
    "    Rcurve = (1+(2Ay+B)**2)**3/2 / |2A|\n",
    "    \n",
    "The y values of my image increase from top to bottom, so if, for example, I wanted to measure the radius of curvature closest to my vehicle, I could evaluate the formula above at the y value corresponding to the bottom of my image, or in Python, at yvalue = image.shape[0]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_curvature(coeff, ploty, ymeters_per_pix=1):\n",
    "    y_eval = np.max(ploty)*ymeters_per_pix\n",
    "    d1_poly = 2*coeff[0]*y_eval + coeff[1]\n",
    "    d2_poly = 2*coeff[0]\n",
    "    return (1+(d1_poly**2))**1.5 / np.absolute(d2_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curve = measure_curvature(coeff_left, ploty)\n",
    "right_curve = measure_curvature(coeff_right, ploty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measureing Physical Lane Curvature\n",
    "#### Measureing How long and wide the section of lane\n",
    "We could do this in detail by measuring out the physical lane in the field of view of the camera, but for this project, I can assume that if I'm projecting a section of lane similar to the images above, the lane is about 30 meaters long and 3.7 meters wide.\n",
    "\n",
    "Let's say that our camera image has 720 relevant pixels in the y-dimension (remember, our image is perspective-transformed), and we'll say roughly 700 relevant pixels in the x-dimension (if from 200 pixels on the left to 900 on the right, or 700). Therefore, to convert from pixels to real-world meter measurements, I can use(in this case):\n",
    "\n",
    "    ym_per_pix = 30/720\n",
    "    xm_per_pix = 3.7/700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ym_per_pix = 30/warped.shape[0]\n",
    "xm_per_pix = 3.7/ (starting_point_r - starting_point_l)\n",
    "real_coeff_left = search_polynomial_around_prior(new_image, target_ly, target_lx, ym_per_pix, xm_per_pix)\n",
    "real_coeff_right = search_polynomial_around_prior(new_image, target_ry, target_rx, ym_per_pix, xm_per_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_curve = measure_curvature(real_coeff_left, ploty, ym_per_pix)\n",
    "right_curve = measure_curvature(real_coeff_right,  ploty, ym_per_pix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(left_curve, 'm', right_curve, 'm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vehicle position with respect to center of the road"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xvalues_on_polynomial_line(coefficient, ploty):\n",
    "    return coefficient[0]*ploty**2 + coefficient[1]*ploty + coefficient[2]\n",
    "\n",
    "def measure_difference_with_center_road(image_width, plotx_left, plotx_right):\n",
    "    for i in range(len(plotx_left)):\n",
    "        left_position = plotx_left[-i-1]\n",
    "        right_position = plotx_right[-i-1]\n",
    "        if (left_position > 0 and left_position < image_width) and\\\n",
    "            (right_position > 0 and right_position < image_width):\n",
    "            difference = (image_width - right_position) - left_position\n",
    "            break\n",
    "    return difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotx_left = get_xvalues_on_polynomial_line(coeff_left, ploty)\n",
    "plotx_right = get_xvalues_on_polynomial_line(coeff_right, ploty)\n",
    "\n",
    "difference = measure_difference_with_center_road(warped.shape[1], plotx_left, plotx_right)\n",
    "if difference > 0:\n",
    "    diff_result = \"Vehicle is {}m right of center\".format(np.round(difference*xm_per_pix, 2))\n",
    "elif difference < 0:\n",
    "    diff_result = \"Vehicle is {}m left of center\".format(np.round(-difference*xm_per_pix, 2))\n",
    "else:\n",
    "    diff_result = \"Vehicle is Just Center!!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_area(image, plotx_left, plotx_right, color=[0,255,0]):\n",
    "    canvas = np.zeros((image.shape[0], image.shape[1], 3), dtype=np.uint8)\n",
    "    mgrid = np.mgrid[0:image.shape[0], 0:image.shape[1]]\n",
    "    is_lane_area =[]\n",
    "    for i, row in enumerate(mgrid[1]):\n",
    "        is_lane = (row > plotx_left[i]) & (row < plotx_right[i])\n",
    "        is_lane_area.append(is_lane)\n",
    "    canvas[is_lane_area] = color\n",
    "    return canvas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_lane_lines(binary_img, ly, lx, ry, yx, l_color=[255,0,0], r_color=[0,0,255]):\n",
    "    out_img = np.dstack((binary_img, binary_img, binary_img))\n",
    "    out_img[ly, lx] = l_color\n",
    "    out_img[ry, yx] = r_color\n",
    "    return out_img.astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_colored_img = draw_lane_area(warped, plotx_left, plotx_right)\n",
    "line_colored_img = color_lane_lines(warped, target_ly, target_lx, target_ry, target_rx)\n",
    "combined = area_colored_img + line_colored_img\n",
    "unwarped = cv2.warpPerspective(combined, Minv, (rimg.shape[1], rimg.shape[0]), flags=cv2.INTER_LINEAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unwarped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mask(initial_img, mask_img, α=0.8, β=0.8, γ=0.):\n",
    "    return cv2.addWeighted(initial_img, α, mask_img, β, γ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_lane_area = draw_mask(unwarped, rimg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"Radius of Curvature = {}(m)\".format(np.round(left_curve, -1))\n",
    "text2 = \"Vehicle is {}\".format(diff_result)\n",
    "masked_lane_area = cv2.putText(masked_lane_area, text1, (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)\n",
    "masked_lane_area = cv2.putText(masked_lane_area, text2, (30, 140), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masked_lane_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(test_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "from calibrate import Calibration\n",
    "from input_holder import InputHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_binary(image):\n",
    "    grad_mag = filter_sobel_gradient_magnitude(image, ksize=5)\n",
    "    grad_dir = filter_gradient_direction(image, ksize=11)\n",
    "    saturate = filter_hls(image, 's')\n",
    "    \n",
    "    binary_grad_mag = create_binary_image(grad_mag, 30, 170)\n",
    "    binary_grad_dir = create_binary_image(grad_dir, 0.8, 1.3)\n",
    "    binary_satulate = create_binary_image(saturate, 150, 300)\n",
    "    \n",
    "    binary = np.zeros_like(binary_grad_dir)\n",
    "    binary[((binary_grad_mag == 1) & (binary_grad_dir == 1) | (binary_satulate == 1))] = 1\n",
    "    return binary\n",
    "    \n",
    "def normalize_coefficients(current_coeffs, prev_coeffs, prev_weight=0.0):\n",
    "    norm_a = prev_coeffs[0]*prev_weight + current_coeffs[0]*(1-prev_weight)   \n",
    "    norm_b = prev_coeffs[1]*prev_weight + current_coeffs[1]*(1-prev_weight)  \n",
    "    return (norm_a, norm_b)\n",
    "\n",
    "def process_image(image, holder):\n",
    "    global is_first_frame\n",
    "    global prev_coeff_left\n",
    "    global prev_coeff_right\n",
    "    \n",
    "    undist_img = cv2.undistort(image, holder.calib.cam_mtx, holder.calib.dist_coeff)\n",
    "    binary_img = to_binary(undist_img)\n",
    "    warped_img = cv2.warpPerspective(binary_img, holder.M, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    print(is_first_frame)\n",
    "    if is_first_frame:\n",
    "        starting_point_l, starting_point_r = get_starting_point_likely(warped_img)        \n",
    "        lx_pixels, ly_pixels, rx_pixels, ry_pixels, lane_colored_img = search_lane_line_pixels(warped_img, starting_point_l, starting_point_r)\n",
    "        coeff_left = np.polyfit(ly_pixels, lx_pixels, 2)\n",
    "        coeff_right = np.polyfit(ry_pixels, rx_pixels, 2)\n",
    "        is_first_frame = False\n",
    "    else:\n",
    "        ly_pixels, lx_pixels = get_search_area_idx(warped_img, prev_coeff_left, 80)\n",
    "        ry_pixels, rx_pixels = get_search_area_idx(warped_img, prev_coeff_right, 80)\n",
    "        coeff_left = search_polynomial_around_prior(image, ly_pixels, lx_pixels)\n",
    "        coeff_right = search_polynomial_around_prior(image, ry_pixels, rx_pixels)\n",
    "    \n",
    "    coeff_left = normalize_coefficients(coeff_left, prev_coeff_left, 0.9)\n",
    "    coeff_right = normalize_coefficients(coeff_right, prev_coeff_right, .9)\n",
    "    \n",
    "    ploty, plotx_l = get_quadratic_plots(warped_img, coeff_left)\n",
    "    ploty, plotx_r = get_quadratic_plots(warped_img, coeff_right)\n",
    "    left_curve = measure_curvature(coeff_left, ploty)\n",
    "    right_curve = measure_curvature(coeff_right, ploty)\n",
    "    \n",
    "    # draw lane mask (lane area & lane line)\n",
    "    area_colored_img = draw_lane_area(warped_img, plotx_l, plotx_r)\n",
    "    line_colored_img = color_lane_lines(warped_img, target_ly, target_lx, target_ry, target_rx)\n",
    "    combined = area_colored_img + line_colored_img\n",
    "    unwarped = cv2.warpPerspective(combined, holder.Minv, (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    masked_lane_area = draw_mask(unwarped, image)\n",
    "    \n",
    "    # get curvature\n",
    "    ym_per_pix = real_ym/warped_img.shape[0]\n",
    "    xm_per_pix = real_xm/ (starting_point_r - starting_point_l)\n",
    "    real_coeff_left = search_polynomial_around_prior(image, target_ly, target_lx, ym_per_pix, xm_per_pix)\n",
    "    real_coeff_right = search_polynomial_around_prior(image, target_ry, target_rx, ym_per_pix, xm_per_pix)\n",
    "    real_left_curve = measure_curvature(real_coeff_left, ploty, ym_per_pix)\n",
    "    real_right_curve = measure_curvature(real_coeff_right,  ploty, ym_per_pix)\n",
    "    \n",
    "    # get difference from center\n",
    "    difference = measure_difference_with_center_road(warped_img.shape[1], plotx_l, plotx_r)\n",
    "    if difference > 0:\n",
    "        diff_result = \"Vehicle is {}m right of center\".format(np.round(difference*xm_per_pix, 2))\n",
    "    elif difference < 0:\n",
    "        diff_result = \"Vehicle is {}m left of center\".format(np.round(-difference*xm_per_pix, 2))\n",
    "    else:\n",
    "        diff_result = \"Vehicle is Just Center!!\"\n",
    "    text1 = \"Radius of Curvature = {}(m)\".format(np.round(left_curve, -1))\n",
    "    text2 = \"Vehicle is {}\".format(diff_result)\n",
    "    masked_lane_area = cv2.putText(masked_lane_area, text1, (30, 80), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)\n",
    "    masked_lane_area = cv2.putText(masked_lane_area, text2, (30, 140), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)    \n",
    "    \n",
    "    prev_coeff_left = coeff_left\n",
    "    prev_coeff_right = coeff_right\n",
    "    \n",
    "    return masked_lane_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera calibration\n",
    "fnames = glob.glob('camera_cal/*.jpg')\n",
    "pattern_size = (9, 6)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "calib = Calibration(fnames, pattern_size, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static values\n",
    "src = np.float32(\n",
    "    [[840, 546],\n",
    "     [1051, 677],\n",
    "     [244, 686],\n",
    "     [453, 546]])\n",
    "dst = np.float32(\n",
    "    [[1051, 463],\n",
    "     [1051, 686],\n",
    "     [245, 686],\n",
    "     [245, 463]])\n",
    "holder = InputHolder(calib, src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prev_coeff_left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-54d293b6d342>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Changable values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mis_first_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprev_coeff_left\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprev_coeff_right\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prev_coeff_left' is not defined"
     ]
    }
   ],
   "source": [
    "# Changable values\n",
    "is_first_frame = True\n",
    "prev_coeff_left\n",
    "prev_coeff_right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prev_coeff_left' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-b338895411cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'output_images/lane_drawed_project_video.mp4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'project_video.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbinary_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'binary_clip.write_videofile(test_video, audio=False)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mfl_image\u001b[1;34m(self, image_func, apply_to)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mfl\u001b[1;34m(self, fun, apply_to, keep_duration)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-182>\u001b[0m in \u001b[0;36mset_make_frame\u001b[1;34m(self, mf)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36moutplace\u001b[1;34m(f, clip, *a, **k)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;34m\"\"\" Applies f(clip.copy(), *a, **k) and returns clip.copy()\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewclip\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewclip\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36mset_make_frame\u001b[1;34m(self, mf)\u001b[0m\n\u001b[0;32m    667\u001b[0m         \"\"\"\n\u001b[0;32m    668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 669\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0moutplace\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-135>\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(f, *a, **kw)\u001b[0m\n\u001b[0;32m     87\u001b[0m         new_kw = {k: fun(v) if k in varnames else v\n\u001b[0;32m     88\u001b[0m                  for (k,v) in kw.items()}\n\u001b[1;32m---> 89\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnew_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mnew_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36mget_frame\u001b[1;34m(self, t)\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\Clip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m         \u001b[1;31m#mf = copy(self.make_frame)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[0mnewclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_make_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkeep_duration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\moviepy\\video\\VideoClip.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(gf, t)\u001b[0m\n\u001b[0;32m    512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mapply_to\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m             \u001b[0mapply_to\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 514\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mgf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_to\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m     \u001b[1;31m# --------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-b338895411cb>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest_video\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'output_images/lane_drawed_project_video.mp4'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVideoFileClip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'project_video.mp4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mbinary_clip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfl_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mprocess_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mholder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'binary_clip.write_videofile(test_video, audio=False)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-98a75015440f>\u001b[0m in \u001b[0;36mprocess_image\u001b[1;34m(image, holder)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mcoeff_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msearch_polynomial_around_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mry_pixels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrx_pixels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mcoeff_left\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoeff_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_coeff_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[0mcoeff_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_coefficients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoeff_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprev_coeff_right\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prev_coeff_left' is not defined"
     ]
    }
   ],
   "source": [
    "test_video = 'output_images/lane_drawed_project_video.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')\n",
    "binary_clip = clip.fl_image(lambda image: process_image(image, holder))\n",
    "%time binary_clip.write_videofile(test_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
